{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2025em1100480-droid/APEX-PROJECT-I/blob/Phase2-Anitha/Neaural_Nexus_Data_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "eb5a2213-d12a-42b5-8766-54d6ac6f16bb",
      "metadata": {
        "id": "eb5a2213-d12a-42b5-8766-54d6ac6f16bb",
        "outputId": "c6cefd16-a1c0-453d-a4b2-561cd3bb7146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World. Lets start our journey towards Data Scien & AI\n"
          ]
        }
      ],
      "source": [
        "print('Hello World. Lets start our journey towards Data Scien & AI')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c1ee4099-657e-4a72-9741-1ed92c6a1844",
      "metadata": {
        "id": "c1ee4099-657e-4a72-9741-1ed92c6a1844"
      },
      "outputs": [],
      "source": [
        "# Import the  library\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76bd929f",
      "metadata": {
        "id": "76bd929f"
      },
      "source": [
        "# Phase - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4017354f-b8fc-4848-be3a-a4f1675da518",
      "metadata": {
        "id": "4017354f-b8fc-4848-be3a-a4f1675da518"
      },
      "source": [
        "### Accessing the Downloaded .csv Dataset File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bc599c6a-bb7d-48ac-abd2-e33c70162cd0",
      "metadata": {
        "id": "bc599c6a-bb7d-48ac-abd2-e33c70162cd0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/2025em1100480-droid/APEX-PROJECT-I/Phase2-Anitha/online_retail.csv\", encoding='latin1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d918cd86-1789-42a4-8cb8-3c533a5d8437",
      "metadata": {
        "id": "d918cd86-1789-42a4-8cb8-3c533a5d8437",
        "outputId": "348347c7-4a89-436c-9e24-db79f652c68b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install the KaggleHub library\n",
        "# The '!' command runs a shell command in Google Colab/Jupyter.\n",
        "!pip install kagglehub\n",
        "\n",
        "# Step 2: Import the necessary libraries\n",
        "import kagglehub\n",
        "\n",
        "import os # This library helps work with file paths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10f71209-c7b2-45ac-860e-f7942ad40592",
      "metadata": {
        "id": "10f71209-c7b2-45ac-860e-f7942ad40592"
      },
      "source": [
        "### The following method ensures that you will always work with the latest version of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "236c3bbe-1f98-44ab-b077-40eab8b464a4",
      "metadata": {
        "id": "236c3bbe-1f98-44ab-b077-40eab8b464a4",
        "outputId": "62151f9d-e3c3-4f2c-b5a9-3ca0511f31d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the dataset...\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Download the dataset\n",
        "# This will download the files to a local folder and return the path.\n",
        "# In Google Colab, it will ask for authentication the first time.\n",
        "print(\"Downloading the dataset...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "abb86980-0f52-4bf8-86b2-8f53e12a84b1",
      "metadata": {
        "id": "abb86980-0f52-4bf8-86b2-8f53e12a84b1",
        "outputId": "6e7b22de-f9ce-4f13-b6a0-185816ffba7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ulrikthygepedersen/online-retail-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.38M/7.38M [00:00<00:00, 180MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/ulrikthygepedersen/online-retail-dataset/versions/2\n"
          ]
        }
      ],
      "source": [
        "# Tells the kagglehub library to find the dataset identified by \"pavansubhasht/ibm-hr-analytics-attrition-dataset\"\n",
        "# Saves the files to a temporary folder on the computer and then stores the location (the path) of that folder in the variable called 'path'\n",
        "path = kagglehub.dataset_download(\"ulrikthygepedersen/online-retail-dataset\")\n",
        "print(f\"Dataset downloaded to: {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "bcc9ebcc-33a5-405d-8c57-9d534eaa68e9",
      "metadata": {
        "id": "bcc9ebcc-33a5-405d-8c57-9d534eaa68e9"
      },
      "outputs": [],
      "source": [
        "file_name = 'online_retail.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f71845bb",
      "metadata": {
        "id": "f71845bb"
      },
      "source": [
        "# Phase - 2\n",
        "\n",
        "### Pre-processing (dataset clean-up)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 80)\n",
        "print(\"PHASE 2: DATA PREPROCESSING & FEATURE ENGINEERING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check missing values\n",
        "print(\"\\n### MISSING VALUES ###\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Remove rows with missing CustomerID\n",
        "df = df.dropna(subset=['CustomerID'])\n",
        "print(f\"✅ Removed rows with missing CustomerID | Shape: {df.shape}\")\n",
        "\n",
        "# Remove cancelled orders\n",
        "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "print(f\"✅ Removed cancelled orders | Shape: {df.shape}\")\n",
        "\n",
        "# Remove negative quantities and prices\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "print(f\"✅ Removed negative values | Shape: {df.shape}\")\n",
        "\n",
        "# Convert InvoiceDate to datetime\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "print(\"✅ Converted InvoiceDate to datetime\")\n",
        "\n",
        "# Convert CustomerID to integer\n",
        "df['CustomerID'] = df['CustomerID'].astype(int)\n",
        "print(\"✅ Converted CustomerID to integer\")\n",
        "\n",
        "# Create TotalPrice column\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "print(\"✅ Created TotalPrice column\")\n",
        "\n",
        "# Extract temporal features\n",
        "df['Year'] = df['InvoiceDate'].dt.year\n",
        "df['Month'] = df['InvoiceDate'].dt.month\n",
        "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
        "print(\"✅ Extracted temporal features\")\n",
        "\n",
        "# Remove outliers\n",
        "q1 = df['UnitPrice'].quantile(0.01)\n",
        "q99 = df['UnitPrice'].quantile(0.99)\n",
        "df = df[(df['UnitPrice'] >= q1) & (df['UnitPrice'] <= q99)]\n",
        "print(f\"✅ Removed outliers | Final shape: {df.shape}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PREPROCESSING COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nUnique Customers: {df['CustomerID'].nunique()}\")\n",
        "print(f\"Unique Products: {df['StockCode'].nunique()}\")\n",
        "print(f\"Countries: {df['Country'].nunique()}\")\n",
        "print(f\"\\nSample Data:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "UyhdLVcH8_5b",
        "outputId": "64f1bb5c-d5bf-4549-c0c9-01f5ddaca87e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "UyhdLVcH8_5b",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PHASE 2: DATA PREPROCESSING & FEATURE ENGINEERING\n",
            "================================================================================\n",
            "\n",
            "### MISSING VALUES ###\n",
            "InvoiceNo           0\n",
            "StockCode           0\n",
            "Description      1454\n",
            "Quantity            0\n",
            "InvoiceDate         0\n",
            "UnitPrice           0\n",
            "CustomerID     135080\n",
            "Country             0\n",
            "dtype: int64\n",
            "✅ Removed rows with missing CustomerID | Shape: (406829, 8)\n",
            "✅ Removed cancelled orders | Shape: (397924, 8)\n",
            "✅ Removed negative values | Shape: (397884, 8)\n",
            "✅ Converted InvoiceDate to datetime\n",
            "✅ Converted CustomerID to integer\n",
            "✅ Created TotalPrice column\n",
            "✅ Extracted temporal features\n",
            "✅ Removed outliers | Final shape: (391159, 12)\n",
            "\n",
            "================================================================================\n",
            "PREPROCESSING COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Unique Customers: 4325\n",
            "Unique Products: 3595\n",
            "Countries: 37\n",
            "\n",
            "Sample Data:\n",
            "  InvoiceNo StockCode                          Description  Quantity  \\\n",
            "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
            "1    536365     71053                  WHITE METAL LANTERN         6   \n",
            "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
            "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
            "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
            "\n",
            "          InvoiceDate  UnitPrice  CustomerID         Country  TotalPrice  \\\n",
            "0 2010-12-01 08:26:00       2.55       17850  United Kingdom       15.30   \n",
            "1 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "2 2010-12-01 08:26:00       2.75       17850  United Kingdom       22.00   \n",
            "3 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "4 2010-12-01 08:26:00       3.39       17850  United Kingdom       20.34   \n",
            "\n",
            "   Year  Month  DayOfWeek  \n",
            "0  2010     12          2  \n",
            "1  2010     12          2  \n",
            "2  2010     12          2  \n",
            "3  2010     12          2  \n",
            "4  2010     12          2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ecc5750",
      "metadata": {
        "id": "4ecc5750"
      },
      "outputs": [],
      "source": [
        "#lets check if we have null values in the dataset\n",
        "\n",
        "print(df.isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcff4424",
      "metadata": {
        "id": "fcff4424"
      },
      "outputs": [],
      "source": [
        "# Remove rows with missing CustomerID\n",
        "df = df.dropna(subset=['CustomerID'])\n",
        "\n",
        "# Remove cancelled orders (InvoiceNo starts with 'C')\n",
        "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
        "\n",
        "# Remove negative Quantity and UnitPrice\n",
        "df = df[(df['Quantity'] > 0) & (df['UnitPrice'] > 0)]\n",
        "\n",
        "# Add TotalPrice column\n",
        "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
        "\n",
        "# Convert InvoiceDate to datetime type\n",
        "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
        "\n",
        "print(\"Data preprocessing complete. Data sample:\")\n",
        "print(df.head())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3e6dfab",
      "metadata": {
        "id": "a3e6dfab"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "#### why we used InoviceDate as index values?\n",
        "#### using InvoiceDate as the index enables us to cluster transactions across all customers within specific time windows, which is essential for Exploratory Data Analysis and understanding sales using time or changes in customer behavior over time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f757cbcc",
      "metadata": {
        "id": "f757cbcc"
      },
      "outputs": [],
      "source": [
        "\n",
        "# InvoiceDate as index\n",
        "df.set_index('InvoiceDate', inplace=True)\n",
        "\n",
        "# Monthly revenue trend\n",
        "df.resample('M')['TotalPrice'].sum().plot(figsize=(10,6), title='Monthly Revenue over Time')\n",
        "plt.ylabel('Revenue')\n",
        "plt.show()\n",
        "\n",
        "# Top 10 countries by revenue\n",
        "df_reset = df.reset_index()\n",
        "country_sales = df_reset.groupby('Country')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
        "country_sales.plot(kind='bar', figsize=(10,5), title='Top 10 Countries by Revenue')\n",
        "plt.ylabel('Revenue')\n",
        "plt.show()\n",
        "\n",
        "# Top customers by total spend\n",
        "customer_sales = df_reset.groupby('CustomerID')['TotalPrice'].sum().sort_values(ascending=False).head(10)\n",
        "customer_sales.plot(kind='bar', figsize=(10,5), title='Top Customers by Total Spend')\n",
        "plt.ylabel('Total Spend')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663c8f5a",
      "metadata": {
        "id": "663c8f5a"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d88a1c",
      "metadata": {
        "id": "94d88a1c"
      },
      "outputs": [],
      "source": [
        "# Calculate latest date plus one day for Recency calculation\n",
        "latest_date = df.index.max() + pd.Timedelta(days=1)\n",
        "\n",
        "# Group by CustomerID and calculate RFM metrics\n",
        "grouped = df_reset.groupby('CustomerID')\n",
        "rfm = grouped.agg({\n",
        "    'InvoiceDate': lambda x: (latest_date - x.max()).days,\n",
        "    'InvoiceNo': 'nunique',\n",
        "    'TotalPrice': 'sum'\n",
        "})\n",
        "rfm.rename(columns={'InvoiceDate': 'Recency', 'InvoiceNo': 'Frequency', 'TotalPrice': 'Monetary'}, inplace=True)\n",
        "\n",
        "# Behavioral features\n",
        "extra = grouped.agg({\n",
        "    'Quantity': ['sum', 'mean'],\n",
        "    'TotalPrice': 'mean',\n",
        "    'StockCode': 'nunique'\n",
        "})\n",
        "extra.columns = ['TotalQuantity', 'AvgQuantity', 'AvgSpend', 'ProductDiversity']\n",
        "\n",
        "# Merge behavioral features with RFM\n",
        "df_rfm = rfm.merge(extra, on='CustomerID')\n",
        "print(df_rfm.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5021a844",
      "metadata": {
        "id": "5021a844"
      },
      "source": [
        "\n",
        "## The RFM model explained\n",
        "#### The RFM model is based on the idea that a customer's past behavior is a good predictor of their future behavior. The three components are:\n",
        "#### Recency: Measures how recently a customer made a purchase. The more recent the transaction, the more likely the customer is to respond to future promotions.\n",
        "#### Frequency: Measures how often a customer makes a purchase within a given time period. Frequent buyers are generally more engaged and loyal.\n",
        "#### Monetary Value: Measures how much a customer spends. High-spending customers are more valuable and should be treated accordingly.\n",
        "\n",
        "### RFM Scoring with quantiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9b67e1",
      "metadata": {
        "id": "1a9b67e1"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_rfm['R_Score'] = pd.qcut(df_rfm['Recency'], 5, labels=[5,4,3,2,1])\n",
        "df_rfm['F_Score'] = pd.qcut(df_rfm['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])\n",
        "df_rfm['M_Score'] = pd.qcut(df_rfm['Monetary'], 5, labels=[1,2,3,4,5])\n",
        "\n",
        "# Compute combined RFM score\n",
        "df_rfm['RFM_Score'] = df_rfm[['R_Score', 'F_Score', 'M_Score']].astype(int).sum(axis=1)\n",
        "\n",
        "print(df_rfm[['Recency', 'Frequency', 'Monetary', 'R_Score', 'F_Score', 'M_Score', 'RFM_Score']].head())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"Phase 2: Data preprocessing - removed nulls, outliers, cancelled orders\"\n",
        "!git push origin Phase2-Anitha"
      ],
      "metadata": {
        "id": "5nJUkNES-foF",
        "outputId": "db543117-0adc-4efc-90f6-a364919ea49b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "5nJUkNES-foF",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}